{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxAgMSPcsz8I0r/ZvBCVTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelrahmanTamer11/Named-Entity-Recognition-NER-Corpus/blob/main/Named_Entity_Recognition_(NER)_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/ner.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# No need for ast.literal_eval, directly use the 'Sentence' column and split the sentences into words\n",
        "sentences = [sentence.split() for sentence in data['Sentence'].tolist()]\n",
        "tags = [tag.strip('[]').replace(\"'\", \"\").split(', ') for tag in data['Tag'].tolist()]\n",
        "\n",
        "# Check the first few examples to ensure the processing is correct\n",
        "print(sentences[:2], tags[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmtkACOYRCiI",
        "outputId": "03bf9532-57d8-4b1e-b078-90a3345b5b1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'], ['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined', 'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans', 'as', '\"', 'Bush', 'Number', 'One', 'Terrorist', '\"', 'and', '\"', 'Stop', 'the', 'Bombings', '.', '\"']] [['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Create a vocabulary for words and tags\n",
        "words = list(set([word for sentence in sentences for word in sentence]))\n",
        "n_words = len(words)\n",
        "\n",
        "tags_set = list(set([tag for tag_list in tags for tag in tag_list]))\n",
        "n_tags = len(tags_set)\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags_set)}\n",
        "\n",
        "# Convert sentences and labels into indices\n",
        "X = [[word2idx[w] for w in s] for s in sentences]\n",
        "y = [[tag2idx[t] for t in t_list] for t_list in tags]\n",
        "\n",
        "# Padding the sequences\n",
        "max_len = 50\n",
        "X = pad_sequences(X, maxlen=max_len, padding=\"post\")\n",
        "y = pad_sequences(y, maxlen=max_len, padding=\"post\")\n"
      ],
      "metadata": {
        "id": "dUbm3mxJbhB3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_len = 50\n",
        "\n",
        "# Pad the input sentences and tag sequences\n",
        "X = pad_sequences([[word2idx.get(w, 0) for w in s] for s in sentences], maxlen=max_len, padding=\"post\")\n",
        "y = pad_sequences([[tag2idx.get(t, 0) for t in tag_seq] for tag_seq in tags], maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Convert target labels (y) to categorical format\n",
        "y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n",
        "\n",
        "# Build the NER model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=n_words, output_dim=50, input_length=max_len),\n",
        "    Dropout(0.1),\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
        "    TimeDistributed(Dense(n_tags, activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, batch_size=32, epochs=5, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-B20fkvdR_Y",
        "outputId": "4734ca7e-87b9-44e5-bfcf-5d342bcef21d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 134ms/step - accuracy: 0.9220 - loss: 0.3219 - val_accuracy: 0.9824 - val_loss: 0.0590\n",
            "Epoch 2/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 137ms/step - accuracy: 0.9850 - loss: 0.0505 - val_accuracy: 0.9851 - val_loss: 0.0487\n",
            "Epoch 3/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 133ms/step - accuracy: 0.9888 - loss: 0.0365 - val_accuracy: 0.9857 - val_loss: 0.0471\n",
            "Epoch 4/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 132ms/step - accuracy: 0.9906 - loss: 0.0297 - val_accuracy: 0.9860 - val_loss: 0.0465\n",
            "Epoch 5/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 133ms/step - accuracy: 0.9919 - loss: 0.0253 - val_accuracy: 0.9858 - val_loss: 0.0478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Convert indices back to entity labels\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}\n",
        "\n",
        "def get_tags(y_pred, y_true):\n",
        "    pred_tags = [[idx2tag[np.argmax(pred)] for pred in p] for p in y_pred]\n",
        "    true_tags = [[idx2tag[np.argmax(true)] for true in t] for t in y_true]\n",
        "    return pred_tags, true_tags\n",
        "\n",
        "# Get predictions\n",
        "pred_tags, true_tags = get_tags(y_pred, y)\n",
        "\n",
        "# Print the evaluation report\n",
        "print(classification_report(true_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UsdqjgedT5w",
        "outputId": "3d6918f2-cb77-4ba1-a577-1c1f4893b0ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 29ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.40      0.09      0.15       401\n",
            "         eve       0.43      0.39      0.41       307\n",
            "         geo       0.91      0.92      0.91     37633\n",
            "         gpe       0.97      0.95      0.96     15859\n",
            "         nat       0.59      0.39      0.47       199\n",
            "         org       0.77      0.83      0.80     20130\n",
            "         per       0.86      0.83      0.84     16978\n",
            "         tim       1.00      1.00      1.00   1370401\n",
            "\n",
            "   micro avg       0.99      0.99      0.99   1461908\n",
            "   macro avg       0.74      0.67      0.69   1461908\n",
            "weighted avg       0.99      0.99      0.99   1461908\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to get the predicted tags for a given sentence\n",
        "def predict_entities(sentence, model, word2idx, idx2tag, max_len):\n",
        "    # Tokenize and pad the sentence\n",
        "    tokens = sentence.split()\n",
        "    tokenized_sentence = [word2idx.get(w, 0) for w in tokens]  # Convert words to indices\n",
        "    padded_sentence = pad_sequences([tokenized_sentence], maxlen=max_len, padding='post')\n",
        "\n",
        "    # Get predictions\n",
        "    pred = model.predict(padded_sentence)\n",
        "\n",
        "    # Convert predictions back to tags\n",
        "    pred_tags = [idx2tag[np.argmax(p)] for p in pred[0]]\n",
        "\n",
        "    # Pair each word with its predicted tag\n",
        "    result = list(zip(tokens, pred_tags[:len(tokens)]))  # Cut off padding\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}  # Reverse the tag dictionary\n",
        "\n",
        "# Test the function with an example sentence\n",
        "sentence = 'Google'\n",
        "predicted_entities = predict_entities(sentence, model, word2idx, idx2tag, max_len)\n",
        "\n",
        "# Print the result\n",
        "for word, tag in predicted_entities:\n",
        "    print(f\"{word}: {tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gPBBwz3jYWP",
        "outputId": "f5060d06-abe1-4caa-e556-cc4e6c706c81"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Google: B-org\n"
          ]
        }
      ]
    }
  ]
}