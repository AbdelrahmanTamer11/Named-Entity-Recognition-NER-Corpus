{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqhOfKYL56vXxcJMa/LFzt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelrahmanTamer11/Named-Entity-Recognition-NER-Corpus/blob/main/Named_Entity_Recognition_(NER)_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/ner.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# No need for ast.literal_eval, directly use the 'Sentence' column and split the sentences into words\n",
        "sentences = [sentence.split() for sentence in data['Sentence'].tolist()]\n",
        "tags = [tag.strip('[]').replace(\"'\", \"\").split(', ') for tag in data['Tag'].tolist()]\n",
        "\n"
      ],
      "metadata": {
        "id": "KmtkACOYRCiI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Create a vocabulary for words and tags\n",
        "words = list(set([word for sentence in sentences for word in sentence]))\n",
        "n_words = len(words)\n",
        "\n",
        "tags_set = list(set([tag for tag_list in tags for tag in tag_list]))\n",
        "n_tags = len(tags_set)\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags_set)}\n",
        "\n",
        "# Convert sentences and labels into indices\n",
        "X = [[word2idx[w] for w in s] for s in sentences]\n",
        "y = [[tag2idx[t] for t in t_list] for t_list in tags]\n",
        "\n",
        "# Padding the sequences\n",
        "max_len = 50\n",
        "X = pad_sequences(X, maxlen=max_len, padding=\"post\")\n",
        "y = pad_sequences(y, maxlen=max_len, padding=\"post\")\n"
      ],
      "metadata": {
        "id": "dUbm3mxJbhB3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_len = 50\n",
        "\n",
        "# Pad the input sentences and tag sequences\n",
        "X = pad_sequences([[word2idx.get(w, 0) for w in s] for s in sentences], maxlen=max_len, padding=\"post\")\n",
        "y = pad_sequences([[tag2idx.get(t, 0) for t in tag_seq] for tag_seq in tags], maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Convert target labels (y) to categorical format\n",
        "y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n",
        "\n",
        "# Build the NER model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=n_words, output_dim=50, input_length=max_len),\n",
        "    Dropout(0.1),\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
        "    TimeDistributed(Dense(n_tags, activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, batch_size=32, epochs=5, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-B20fkvdR_Y",
        "outputId": "f8b0564b-43ab-4c47-b8fd-9601b5301455"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 134ms/step - accuracy: 0.9240 - loss: 0.3252 - val_accuracy: 0.9826 - val_loss: 0.0582\n",
            "Epoch 2/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 131ms/step - accuracy: 0.9853 - loss: 0.0498 - val_accuracy: 0.9853 - val_loss: 0.0476\n",
            "Epoch 3/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 132ms/step - accuracy: 0.9890 - loss: 0.0357 - val_accuracy: 0.9859 - val_loss: 0.0465\n",
            "Epoch 4/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 131ms/step - accuracy: 0.9906 - loss: 0.0297 - val_accuracy: 0.9861 - val_loss: 0.0467\n",
            "Epoch 5/5\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 130ms/step - accuracy: 0.9918 - loss: 0.0252 - val_accuracy: 0.9861 - val_loss: 0.0476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Convert indices back to entity labels\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}\n",
        "\n",
        "def get_tags(y_pred, y_true):\n",
        "    pred_tags = [[idx2tag[np.argmax(pred)] for pred in p] for p in y_pred]\n",
        "    true_tags = [[idx2tag[np.argmax(true)] for true in t] for t in y_true]\n",
        "    return pred_tags, true_tags\n",
        "\n",
        "# Get predictions\n",
        "pred_tags, true_tags = get_tags(y_pred, y)\n",
        "\n",
        "# Print the evaluation report\n",
        "print(classification_report(true_tags, pred_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UsdqjgedT5w",
        "outputId": "7acdc1c3-5a6e-4c5d-f2e7-28b5d009ea08"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.49      0.34      0.40       401\n",
            "         eve       0.44      0.44      0.44       307\n",
            "         geo       0.89      0.93      0.91     37633\n",
            "         gpe       0.97      0.95      0.96     15859\n",
            "         nat       0.62      0.35      0.45       199\n",
            "         org       0.83      0.78      0.80     20130\n",
            "         per       0.82      0.86      0.84     16978\n",
            "         tim       1.00      1.00      1.00   1370401\n",
            "\n",
            "   micro avg       0.99      0.99      0.99   1461908\n",
            "   macro avg       0.76      0.71      0.73   1461908\n",
            "weighted avg       0.99      0.99      0.99   1461908\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to get the predicted tags for a given sentence\n",
        "def predict_entities(sentence, model, word2idx, idx2tag, max_len):\n",
        "    # Tokenize and pad the sentence\n",
        "    tokens = sentence.split()\n",
        "    tokenized_sentence = [word2idx.get(w, 0) for w in tokens]  # Convert words to indices\n",
        "    padded_sentence = pad_sequences([tokenized_sentence], maxlen=max_len, padding='post')\n",
        "\n",
        "    # Get predictions\n",
        "    pred = model.predict(padded_sentence)\n",
        "\n",
        "    # Convert predictions back to tags\n",
        "    pred_tags = [idx2tag[np.argmax(p)] for p in pred[0]]\n",
        "\n",
        "    # Pair each word with its predicted tag\n",
        "    result = list(zip(tokens, pred_tags[:len(tokens)]))  # Cut off padding\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}  # Reverse the tag dictionary\n",
        "\n",
        "# Test the function with an example sentence\n",
        "sentence = 'Google'\n",
        "predicted_entities = predict_entities(sentence, model, word2idx, idx2tag, max_len)\n",
        "\n",
        "# Print the result\n",
        "for word, tag in predicted_entities:\n",
        "    print(f\"{word}: {tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gPBBwz3jYWP",
        "outputId": "e441bae6-4458-4568-807a-bddb22b8bd4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Google: B-org\n"
          ]
        }
      ]
    }
  ]
}